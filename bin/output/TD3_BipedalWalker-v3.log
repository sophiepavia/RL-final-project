Using cpu device
Training td3 on BipedalWalker-v3...
Logging to ./tensorboard/td3_BipedalWalker-v3/TD3_1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 86.2     |
|    ep_rew_mean     | -108     |
| time/              |          |
|    episodes        | 4        |
|    fps             | 3376     |
|    time_elapsed    | 0        |
|    total_timesteps | 345      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 458      |
|    ep_rew_mean     | -103     |
| time/              |          |
|    episodes        | 8        |
|    fps             | 2728     |
|    time_elapsed    | 1        |
|    total_timesteps | 3665     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 582      |
|    ep_rew_mean     | -99.7    |
| time/              |          |
|    episodes        | 12       |
|    fps             | 2758     |
|    time_elapsed    | 2        |
|    total_timesteps | 6989     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 455      |
|    ep_rew_mean     | -102     |
| time/              |          |
|    episodes        | 16       |
|    fps             | 2781     |
|    time_elapsed    | 2        |
|    total_timesteps | 7287     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 378      |
|    ep_rew_mean     | -102     |
| time/              |          |
|    episodes        | 20       |
|    fps             | 2780     |
|    time_elapsed    | 2        |
|    total_timesteps | 7558     |
---------------------------------
Eval num_timesteps=10000, episode_reward=-5.29 +/- 1.14
Episode length: 1600.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.6e+03  |
|    mean_reward     | -5.29    |
| time/              |          |
|    total_timesteps | 10000    |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 392      |
|    ep_rew_mean     | -103     |
| time/              |          |
|    episodes        | 24       |
|    fps             | 902      |
|    time_elapsed    | 11       |
|    total_timesteps | 10145    |
| train/             |          |
|    actor_loss      | 0.414    |
|    critic_loss     | 0.303    |
|    learning_rate   | 0.001    |
|    n_updates       | 144      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 358      |
|    ep_rew_mean     | -107     |
| time/              |          |
|    episodes        | 28       |
|    fps             | 702      |
|    time_elapsed    | 15       |
|    total_timesteps | 10768    |
| train/             |          |
|    actor_loss      | 0.0706   |
|    critic_loss     | 64.8     |
|    learning_rate   | 0.001    |
|    n_updates       | 767      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 324      |
|    ep_rew_mean     | -108     |
| time/              |          |
|    episodes        | 32       |
|    fps             | 615      |
|    time_elapsed    | 18       |
|    total_timesteps | 11115    |
| train/             |          |
|    actor_loss      | -0.137   |
|    critic_loss     | 28.5     |
|    learning_rate   | 0.001    |
|    n_updates       | 1114     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 337      |
|    ep_rew_mean     | -107     |
| time/              |          |
|    episodes        | 36       |
|    fps             | 373      |
|    time_elapsed    | 34       |
|    total_timesteps | 12885    |
| train/             |          |
|    actor_loss      | 0.534    |
|    critic_loss     | 0.685    |
|    learning_rate   | 0.001    |
|    n_updates       | 2884     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 313      |
|    ep_rew_mean     | -107     |
| time/              |          |
|    episodes        | 40       |
|    fps             | 348      |
|    time_elapsed    | 38       |
|    total_timesteps | 13264    |
| train/             |          |
|    actor_loss      | 0.907    |
|    critic_loss     | 1.64     |
|    learning_rate   | 0.001    |
|    n_updates       | 3263     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 291      |
|    ep_rew_mean     | -107     |
| time/              |          |
|    episodes        | 44       |
|    fps             | 330      |
|    time_elapsed    | 40       |
|    total_timesteps | 13556    |
| train/             |          |
|    actor_loss      | 0.89     |
|    critic_loss     | 6.93     |
|    learning_rate   | 0.001    |
|    n_updates       | 3555     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 271      |
|    ep_rew_mean     | -107     |
| time/              |          |
|    episodes        | 48       |
|    fps             | 320      |
|    time_elapsed    | 43       |
|    total_timesteps | 13780    |
| train/             |          |
|    actor_loss      | 1.31     |
|    critic_loss     | 160      |
|    learning_rate   | 0.001    |
|    n_updates       | 3779     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 261      |
|    ep_rew_mean     | -108     |
| time/              |          |
|    episodes        | 52       |
|    fps             | 296      |
|    time_elapsed    | 48       |
|    total_timesteps | 14336    |
| train/             |          |
|    actor_loss      | -0.292   |
|    critic_loss     | 1.56     |
|    learning_rate   | 0.001    |
|    n_updates       | 4335     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 263      |
|    ep_rew_mean     | -109     |
| time/              |          |
|    episodes        | 56       |
|    fps             | 260      |
|    time_elapsed    | 59       |
|    total_timesteps | 15486    |
| train/             |          |
|    actor_loss      | -0.169   |
|    critic_loss     | 2.33     |
|    learning_rate   | 0.001    |
|    n_updates       | 5485     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 255      |
|    ep_rew_mean     | -110     |
| time/              |          |
|    episodes        | 60       |
|    fps             | 245      |
|    time_elapsed    | 65       |
|    total_timesteps | 16076    |
| train/             |          |
|    actor_loss      | -0.596   |
|    critic_loss     | 2.21     |
|    learning_rate   | 0.001    |
|    n_updates       | 6075     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 243      |
|    ep_rew_mean     | -109     |
| time/              |          |
|    episodes        | 64       |
|    fps             | 241      |
|    time_elapsed    | 67       |
|    total_timesteps | 16319    |
| train/             |          |
|    actor_loss      | 0.884    |
|    critic_loss     | 192      |
|    learning_rate   | 0.001    |
|    n_updates       | 6318     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 233      |
|    ep_rew_mean     | -109     |
| time/              |          |
|    episodes        | 68       |
|    fps             | 236      |
|    time_elapsed    | 69       |
|    total_timesteps | 16561    |
| train/             |          |
|    actor_loss      | 0.328    |
|    critic_loss     | 0.49     |
|    learning_rate   | 0.001    |
|    n_updates       | 6560     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 223      |
|    ep_rew_mean     | -109     |
| time/              |          |
|    episodes        | 72       |
|    fps             | 232      |
|    time_elapsed    | 72       |
|    total_timesteps | 16809    |
| train/             |          |
|    actor_loss      | 1.39     |
|    critic_loss     | 0.497    |
|    learning_rate   | 0.001    |
|    n_updates       | 6808     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 214      |
|    ep_rew_mean     | -109     |
| time/              |          |
|    episodes        | 76       |
|    fps             | 228      |
|    time_elapsed    | 74       |
|    total_timesteps | 16997    |
| train/             |          |
|    actor_loss      | 1.43     |
|    critic_loss     | 1.44     |
|    learning_rate   | 0.001    |
|    n_updates       | 6996     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 205      |
|    ep_rew_mean     | -109     |
| time/              |          |
|    episodes        | 80       |
|    fps             | 225      |
|    time_elapsed    | 76       |
|    total_timesteps | 17184    |
| train/             |          |
|    actor_loss      | 0.926    |
|    critic_loss     | 4.51     |
|    learning_rate   | 0.001    |
|    n_updates       | 7183     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 199      |
|    ep_rew_mean     | -108     |
| time/              |          |
|    episodes        | 84       |
|    fps             | 220      |
|    time_elapsed    | 78       |
|    total_timesteps | 17437    |
| train/             |          |
|    actor_loss      | -0.199   |
|    critic_loss     | 0.599    |
|    learning_rate   | 0.001    |
|    n_updates       | 7436     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 192      |
|    ep_rew_mean     | -108     |
| time/              |          |
|    episodes        | 88       |
|    fps             | 216      |
|    time_elapsed    | 81       |
|    total_timesteps | 17672    |
| train/             |          |
|    actor_loss      | 1.25     |
|    critic_loss     | 3.55     |
|    learning_rate   | 0.001    |
|    n_updates       | 7671     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 187      |
|    ep_rew_mean     | -108     |
| time/              |          |
|    episodes        | 92       |
|    fps             | 211      |
|    time_elapsed    | 84       |
|    total_timesteps | 17975    |
| train/             |          |
|    actor_loss      | 2.46     |
|    critic_loss     | 0.802    |
|    learning_rate   | 0.001    |
|    n_updates       | 7974     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 184      |
|    ep_rew_mean     | -108     |
| time/              |          |
|    episodes        | 96       |
|    fps             | 206      |
|    time_elapsed    | 88       |
|    total_timesteps | 18365    |
| train/             |          |
|    actor_loss      | 1.06     |
|    critic_loss     | 0.568    |
|    learning_rate   | 0.001    |
|    n_updates       | 8364     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 180      |
|    ep_rew_mean     | -107     |
| time/              |          |
|    episodes        | 100      |
|    fps             | 202      |
|    time_elapsed    | 92       |
|    total_timesteps | 18700    |
| train/             |          |
|    actor_loss      | 3.63     |
|    critic_loss     | 1.07     |
|    learning_rate   | 0.001    |
|    n_updates       | 8699     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 179      |
|    ep_rew_mean     | -107     |
| time/              |          |
|    episodes        | 104      |
|    fps             | 199      |
|    time_elapsed    | 95       |
|    total_timesteps | 19030    |
| train/             |          |
|    actor_loss      | 3.06     |
|    critic_loss     | 1.81     |
|    learning_rate   | 0.001    |
|    n_updates       | 9029     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 150      |
|    ep_rew_mean     | -108     |
| time/              |          |
|    episodes        | 108      |
|    fps             | 195      |
|    time_elapsed    | 99       |
|    total_timesteps | 19455    |
| train/             |          |
|    actor_loss      | 3.26     |
|    critic_loss     | 1.53     |
|    learning_rate   | 0.001    |
|    n_updates       | 9454     |
---------------------------------
Eval num_timesteps=20000, episode_reward=-138.95 +/- 25.53
Episode length: 276.40 +/- 280.93
---------------------------------
| eval/              |          |
|    mean_ep_length  | 276      |
|    mean_reward     | -139     |
| time/              |          |
|    total_timesteps | 20000    |
| train/             |          |
|    actor_loss      | 3.58     |
|    critic_loss     | 1.83     |
|    learning_rate   | 0.001    |
|    n_updates       | 9999     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 124      |
|    ep_rew_mean     | -109     |
| time/              |          |
|    episodes        | 112      |
|    fps             | 186      |
|    time_elapsed    | 108      |
|    total_timesteps | 20255    |
| train/             |          |
|    actor_loss      | 3.17     |
|    critic_loss     | 1.53     |
|    learning_rate   | 0.001    |
|    n_updates       | 10254    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 125      |
|    ep_rew_mean     | -109     |
| time/              |          |
|    episodes        | 116      |
|    fps             | 183      |
|    time_elapsed    | 112      |
|    total_timesteps | 20650    |
| train/             |          |
|    actor_loss      | 3.2      |
|    critic_loss     | 7.8      |
|    learning_rate   | 0.001    |
|    n_updates       | 10649    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 125      |
|    ep_rew_mean     | -110     |
| time/              |          |
|    episodes        | 120      |
|    fps             | 180      |
|    time_elapsed    | 115      |
|    total_timesteps | 20964    |
| train/             |          |
|    actor_loss      | 5.74     |
|    critic_loss     | 3.58     |
|    learning_rate   | 0.001    |
|    n_updates       | 10963    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 111      |
|    ep_rew_mean     | -110     |
| time/              |          |
|    episodes        | 124      |
|    fps             | 177      |
|    time_elapsed    | 120      |
|    total_timesteps | 21406    |
| train/             |          |
|    actor_loss      | 5.87     |
|    critic_loss     | 3.93     |
|    learning_rate   | 0.001    |
|    n_updates       | 11405    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 108      |
|    ep_rew_mean     | -110     |
| time/              |          |
|    episodes        | 128      |
|    fps             | 175      |
|    time_elapsed    | 123      |
|    total_timesteps | 21744    |
| train/             |          |
|    actor_loss      | 4.11     |
|    critic_loss     | 3.54     |
|    learning_rate   | 0.001    |
|    n_updates       | 11743    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 118      |
|    ep_rew_mean     | -111     |
| time/              |          |
|    episodes        | 132      |
|    fps             | 167      |
|    time_elapsed    | 137      |
|    total_timesteps | 23096    |
| train/             |          |
|    actor_loss      | 5.77     |
|    critic_loss     | 3.19     |
|    learning_rate   | 0.001    |
|    n_updates       | 13095    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 105      |
|    ep_rew_mean     | -111     |
| time/              |          |
|    episodes        | 136      |
|    fps             | 165      |
|    time_elapsed    | 142      |
|    total_timesteps | 23501    |
| train/             |          |
|    actor_loss      | 7.75     |
|    critic_loss     | 10.8     |
|    learning_rate   | 0.001    |
|    n_updates       | 13500    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 104      |
|    ep_rew_mean     | -111     |
| time/              |          |
|    episodes        | 140      |
|    fps             | 163      |
|    time_elapsed    | 145      |
|    total_timesteps | 23808    |
| train/             |          |
|    actor_loss      | 4.49     |
|    critic_loss     | 3.88     |
|    learning_rate   | 0.001    |
|    n_updates       | 13807    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 105      |
|    ep_rew_mean     | -111     |
| time/              |          |
|    episodes        | 144      |
|    fps             | 161      |
|    time_elapsed    | 149      |
|    total_timesteps | 24232    |
| train/             |          |
|    actor_loss      | 5.41     |
|    critic_loss     | 8.03     |
|    learning_rate   | 0.001    |
|    n_updates       | 14231    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 107      |
|    ep_rew_mean     | -111     |
| time/              |          |
|    episodes        | 148      |
|    fps             | 160      |
|    time_elapsed    | 154      |
|    total_timesteps | 24662    |
| train/             |          |
|    actor_loss      | 10.9     |
|    critic_loss     | 3.61     |
|    learning_rate   | 0.001    |
|    n_updates       | 14661    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 127      |
|    ep_rew_mean     | -111     |
| time/              |          |
|    episodes        | 152      |
|    fps             | 150      |
|    time_elapsed    | 180      |
|    total_timesteps | 27218    |
| train/             |          |
|    actor_loss      | 6.99     |
|    critic_loss     | 0.811    |
|    learning_rate   | 0.001    |
|    n_updates       | 17217    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 120      |
|    ep_rew_mean     | -110     |
| time/              |          |
|    episodes        | 156      |
|    fps             | 149      |
|    time_elapsed    | 184      |
|    total_timesteps | 27594    |
| train/             |          |
|    actor_loss      | 8.8      |
|    critic_loss     | 3.05     |
|    learning_rate   | 0.001    |
|    n_updates       | 17593    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 129      |
|    ep_rew_mean     | -109     |
| time/              |          |
|    episodes        | 160      |
|    fps             | 144      |
|    time_elapsed    | 200      |
|    total_timesteps | 29092    |
| train/             |          |
|    actor_loss      | 5.91     |
|    critic_loss     | 0.892    |
|    learning_rate   | 0.001    |
|    n_updates       | 19091    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 135      |
|    ep_rew_mean     | -109     |
| time/              |          |
|    episodes        | 164      |
|    fps             | 142      |
|    time_elapsed    | 211      |
|    total_timesteps | 29989    |
| train/             |          |
|    actor_loss      | 8.77     |
|    critic_loss     | 5        |
|    learning_rate   | 0.001    |
|    n_updates       | 19988    |
---------------------------------
Eval num_timesteps=30000, episode_reward=-97.34 +/- 1.86
Episode length: 99.00 +/- 11.66
---------------------------------
| eval/              |          |
|    mean_ep_length  | 99       |
|    mean_reward     | -97.3    |
| time/              |          |
|    total_timesteps | 30000    |
| train/             |          |
|    actor_loss      | 4.15     |
|    critic_loss     | 3.54     |
|    learning_rate   | 0.001    |
|    n_updates       | 19999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 155      |
|    ep_rew_mean     | -110     |
| time/              |          |
|    episodes        | 168      |
|    fps             | 137      |
|    time_elapsed    | 235      |
|    total_timesteps | 32212    |
| train/             |          |
|    actor_loss      | 8.14     |
|    critic_loss     | 1.6      |
|    learning_rate   | 0.001    |
|    n_updates       | 22211    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 163      |
|    ep_rew_mean     | -110     |
| time/              |          |
|    episodes        | 172      |
|    fps             | 134      |
|    time_elapsed    | 246      |
|    total_timesteps | 33230    |
| train/             |          |
|    actor_loss      | 6.44     |
|    critic_loss     | 2.31     |
|    learning_rate   | 0.001    |
|    n_updates       | 23229    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 165      |
|    ep_rew_mean     | -109     |
| time/              |          |
|    episodes        | 176      |
|    fps             | 134      |
|    time_elapsed    | 251      |
|    total_timesteps | 33675    |
| train/             |          |
|    actor_loss      | 6.42     |
|    critic_loss     | 2.3      |
|    learning_rate   | 0.001    |
|    n_updates       | 23674    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 168      |
|    ep_rew_mean     | -109     |
| time/              |          |
|    episodes        | 180      |
|    fps             | 133      |
|    time_elapsed    | 255      |
|    total_timesteps | 34078    |
| train/             |          |
|    actor_loss      | 7.83     |
|    critic_loss     | 3.61     |
|    learning_rate   | 0.001    |
|    n_updates       | 24077    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 183      |
|    ep_rew_mean     | -109     |
| time/              |          |
|    episodes        | 184      |
|    fps             | 130      |
|    time_elapsed    | 275      |
|    total_timesteps | 35929    |
| train/             |          |
|    actor_loss      | 7.19     |
|    critic_loss     | 1.16     |
|    learning_rate   | 0.001    |
|    n_updates       | 25928    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 200      |
|    ep_rew_mean     | -110     |
| time/              |          |
|    episodes        | 188      |
|    fps             | 127      |
|    time_elapsed    | 297      |
|    total_timesteps | 37866    |
| train/             |          |
|    actor_loss      | 13.3     |
|    critic_loss     | 1.36     |
|    learning_rate   | 0.001    |
|    n_updates       | 27865    |
---------------------------------
Eval num_timesteps=40000, episode_reward=-86.85 +/- 10.23
Episode length: 1600.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.6e+03  |
|    mean_reward     | -86.9    |
| time/              |          |
|    total_timesteps | 40000    |
| train/             |          |
|    actor_loss      | 7.72     |
|    critic_loss     | 2        |
|    learning_rate   | 0.001    |
|    n_updates       | 29999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -109     |
| time/              |          |
|    episodes        | 192      |
|    fps             | 119      |
|    time_elapsed    | 364      |
|    total_timesteps | 43457    |
| train/             |          |
|    actor_loss      | 6.66     |
|    critic_loss     | 1.18     |
|    learning_rate   | 0.001    |
|    n_updates       | 33456    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 287      |
|    ep_rew_mean     | -110     |
| time/              |          |
|    episodes        | 196      |
|    fps             | 116      |
|    time_elapsed    | 409      |
|    total_timesteps | 47732    |
| train/             |          |
|    actor_loss      | 7.83     |
|    critic_loss     | 2.4      |
|    learning_rate   | 0.001    |
|    n_updates       | 37731    |
---------------------------------
Eval num_timesteps=50000, episode_reward=-89.89 +/- 7.51
Episode length: 282.60 +/- 130.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 283      |
|    mean_reward     | -89.9    |
| time/              |          |
|    total_timesteps | 50000    |
| train/             |          |
|    actor_loss      | 4.26     |
|    critic_loss     | 1.56     |
|    learning_rate   | 0.001    |
|    n_updates       | 39999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 303      |
|    ep_rew_mean     | -112     |
| time/              |          |
|    episodes        | 200      |
|    fps             | 114      |
|    time_elapsed    | 439      |
|    total_timesteps | 50408    |
| train/             |          |
|    actor_loss      | 4.84     |
|    critic_loss     | 2.46     |
|    learning_rate   | 0.001    |
|    n_updates       | 40407    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 321      |
|    ep_rew_mean     | -112     |
| time/              |          |
|    episodes        | 204      |
|    fps             | 113      |
|    time_elapsed    | 461      |
|    total_timesteps | 52465    |
| train/             |          |
|    actor_loss      | 8.18     |
|    critic_loss     | 2.86     |
|    learning_rate   | 0.001    |
|    n_updates       | 42464    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 341      |
|    ep_rew_mean     | -112     |
| time/              |          |
|    episodes        | 208      |
|    fps             | 112      |
|    time_elapsed    | 487      |
|    total_timesteps | 54966    |
| train/             |          |
|    actor_loss      | 3.87     |
|    critic_loss     | 0.897    |
|    learning_rate   | 0.001    |
|    n_updates       | 44965    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 343      |
|    ep_rew_mean     | -111     |
| time/              |          |
|    episodes        | 212      |
|    fps             | 112      |
|    time_elapsed    | 496      |
|    total_timesteps | 55763    |
| train/             |          |
|    actor_loss      | 6.87     |
|    critic_loss     | 1.29     |
|    learning_rate   | 0.001    |
|    n_updates       | 45762    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 369      |
|    ep_rew_mean     | -110     |
| time/              |          |
|    episodes        | 216      |
|    fps             | 110      |
|    time_elapsed    | 529      |
|    total_timesteps | 58742    |
| train/             |          |
|    actor_loss      | 10.4     |
|    critic_loss     | 2.56     |
|    learning_rate   | 0.001    |
|    n_updates       | 48741    |
---------------------------------
Eval num_timesteps=60000, episode_reward=-121.96 +/- 1.46
Episode length: 92.00 +/- 24.96
---------------------------------
| eval/              |          |
|    mean_ep_length  | 92       |
|    mean_reward     | -122     |
| time/              |          |
|    total_timesteps | 60000    |
| train/             |          |
|    actor_loss      | 1.71     |
|    critic_loss     | 3.81     |
|    learning_rate   | 0.001    |
|    n_updates       | 49999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 385      |
|    ep_rew_mean     | -110     |
| time/              |          |
|    episodes        | 220      |
|    fps             | 109      |
|    time_elapsed    | 566      |
|    total_timesteps | 61963    |
| train/             |          |
|    actor_loss      | 7.31     |
|    critic_loss     | 2.33     |
|    learning_rate   | 0.001    |
|    n_updates       | 51962    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 425      |
|    ep_rew_mean     | -109     |
| time/              |          |
|    episodes        | 224      |
|    fps             | 107      |
|    time_elapsed    | 620      |
|    total_timesteps | 66400    |
| train/             |          |
|    actor_loss      | 6.97     |
|    critic_loss     | 0.881    |
|    learning_rate   | 0.001    |
|    n_updates       | 56399    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 448      |
|    ep_rew_mean     | -108     |
| time/              |          |
|    episodes        | 228      |
|    fps             | 106      |
|    time_elapsed    | 650      |
|    total_timesteps | 69039    |
| train/             |          |
|    actor_loss      | 6.56     |
|    critic_loss     | 0.639    |
|    learning_rate   | 0.001    |
|    n_updates       | 59038    |
---------------------------------
Eval num_timesteps=70000, episode_reward=-83.86 +/- 4.00
Episode length: 1600.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.6e+03  |
|    mean_reward     | -83.9    |
| time/              |          |
|    total_timesteps | 70000    |
| train/             |          |
|    actor_loss      | 6.9      |
|    critic_loss     | 1.18     |
|    learning_rate   | 0.001    |
|    n_updates       | 59999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 477      |
|    ep_rew_mean     | -106     |
| time/              |          |
|    episodes        | 232      |
|    fps             | 102      |
|    time_elapsed    | 721      |
|    total_timesteps | 74014    |
| train/             |          |
|    actor_loss      | 7.3      |
|    critic_loss     | 0.681    |
|    learning_rate   | 0.001    |
|    n_updates       | 64013    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 481      |
|    ep_rew_mean     | -105     |
| time/              |          |
|    episodes        | 236      |
|    fps             | 102      |
|    time_elapsed    | 730      |
|    total_timesteps | 74781    |
| train/             |          |
|    actor_loss      | 4.28     |
|    critic_loss     | 1.85     |
|    learning_rate   | 0.001    |
|    n_updates       | 64780    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 492      |
|    ep_rew_mean     | -105     |
| time/              |          |
|    episodes        | 240      |
|    fps             | 101      |
|    time_elapsed    | 747      |
|    total_timesteps | 76222    |
| train/             |          |
|    actor_loss      | 7.14     |
|    critic_loss     | 3.92     |
|    learning_rate   | 0.001    |
|    n_updates       | 66221    |
---------------------------------
Eval num_timesteps=80000, episode_reward=-48.59 +/- 53.12
Episode length: 975.00 +/- 570.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 975      |
|    mean_reward     | -48.6    |
| time/              |          |
|    total_timesteps | 80000    |
| train/             |          |
|    actor_loss      | 7.7      |
|    critic_loss     | 1.21     |
|    learning_rate   | 0.001    |
|    n_updates       | 69999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 527      |
|    ep_rew_mean     | -102     |
| time/              |          |
|    episodes        | 244      |
|    fps             | 99       |
|    time_elapsed    | 820      |
|    total_timesteps | 81600    |
| train/             |          |
|    actor_loss      | 8.43     |
|    critic_loss     | 0.672    |
|    learning_rate   | 0.001    |
|    n_updates       | 71599    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 587      |
|    ep_rew_mean     | -95.7    |
| time/              |          |
|    episodes        | 248      |
|    fps             | 97       |
|    time_elapsed    | 906      |
|    total_timesteps | 88000    |
| train/             |          |
|    actor_loss      | 6.29     |
|    critic_loss     | 1.45     |
|    learning_rate   | 0.001    |
|    n_updates       | 77999    |
---------------------------------
Eval num_timesteps=90000, episode_reward=-66.79 +/- 13.27
Episode length: 1338.40 +/- 523.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.34e+03 |
|    mean_reward     | -66.8    |
| time/              |          |
|    total_timesteps | 90000    |
| train/             |          |
|    actor_loss      | 7.09     |
|    critic_loss     | 1.84     |
|    learning_rate   | 0.001    |
|    n_updates       | 79999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 605      |
|    ep_rew_mean     | -94      |
| time/              |          |
|    episodes        | 252      |
|    fps             | 94       |
|    time_elapsed    | 978      |
|    total_timesteps | 92773    |
| train/             |          |
|    actor_loss      | 8.14     |
|    critic_loss     | 1.37     |
|    learning_rate   | 0.001    |
|    n_updates       | 82772    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 659      |
|    ep_rew_mean     | -87.8    |
| time/              |          |
|    episodes        | 256      |
|    fps             | 93       |
|    time_elapsed    | 1054     |
|    total_timesteps | 98539    |
| train/             |          |
|    actor_loss      | 5.22     |
|    critic_loss     | 0.743    |
|    learning_rate   | 0.001    |
|    n_updates       | 88538    |
---------------------------------
Eval num_timesteps=100000, episode_reward=47.99 +/- 60.51
Episode length: 1600.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.6e+03  |
|    mean_reward     | 48       |
| time/              |          |
|    total_timesteps | 100000   |
| train/             |          |
|    actor_loss      | 4.06     |
|    critic_loss     | 0.882    |
|    learning_rate   | 0.001    |
|    n_updates       | 89999    |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 708      |
|    ep_rew_mean     | -79.1    |
| time/              |          |
|    episodes        | 260      |
|    fps             | 91       |
|    time_elapsed    | 1165     |
|    total_timesteps | 106400   |
| train/             |          |
|    actor_loss      | 5.78     |
|    critic_loss     | 1.41     |
|    learning_rate   | 0.001    |
|    n_updates       | 96399    |
---------------------------------
Eval num_timesteps=110000, episode_reward=58.75 +/- 94.75
Episode length: 1225.40 +/- 465.29
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.23e+03 |
|    mean_reward     | 58.7     |
| time/              |          |
|    total_timesteps | 110000   |
| train/             |          |
|    actor_loss      | 2.77     |
|    critic_loss     | 0.653    |
|    learning_rate   | 0.001    |
|    n_updates       | 99999    |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 763      |
|    ep_rew_mean     | -69.4    |
| time/              |          |
|    episodes        | 264      |
|    fps             | 89       |
|    time_elapsed    | 1264     |
|    total_timesteps | 113200   |
| train/             |          |
|    actor_loss      | 2.98     |
|    critic_loss     | 1.55     |
|    learning_rate   | 0.001    |
|    n_updates       | 103199   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 805      |
|    ep_rew_mean     | -59      |
| time/              |          |
|    episodes        | 268      |
|    fps             | 88       |
|    time_elapsed    | 1355     |
|    total_timesteps | 119600   |
| train/             |          |
|    actor_loss      | 6.37     |
|    critic_loss     | 1.27     |
|    learning_rate   | 0.001    |
|    n_updates       | 109599   |
---------------------------------
Eval num_timesteps=120000, episode_reward=132.40 +/- 3.73
Episode length: 1600.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.6e+03  |
|    mean_reward     | 132      |
| time/              |          |
|    total_timesteps | 120000   |
| train/             |          |
|    actor_loss      | 2.65     |
|    critic_loss     | 2.73     |
|    learning_rate   | 0.001    |
|    n_updates       | 109999   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 838      |
|    ep_rew_mean     | -53      |
| time/              |          |
|    episodes        | 272      |
|    fps             | 86       |
|    time_elapsed    | 1429     |
|    total_timesteps | 124317   |
| train/             |          |
|    actor_loss      | 4.32     |
|    critic_loss     | 0.686    |
|    learning_rate   | 0.001    |
|    n_updates       | 114316   |
---------------------------------
Eval num_timesteps=130000, episode_reward=108.51 +/- 33.23
Episode length: 1600.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.6e+03  |
|    mean_reward     | 109      |
| time/              |          |
|    total_timesteps | 130000   |
| train/             |          |
|    actor_loss      | 4.95     |
|    critic_loss     | 0.893    |
|    learning_rate   | 0.001    |
|    n_updates       | 119999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 898      |
|    ep_rew_mean     | -45.9    |
| time/              |          |
|    episodes        | 276      |
|    fps             | 85       |
|    time_elapsed    | 1544     |
|    total_timesteps | 131600   |
| train/             |          |
|    actor_loss      | 5.72     |
|    critic_loss     | 0.701    |
|    learning_rate   | 0.001    |
|    n_updates       | 121599   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 957      |
|    ep_rew_mean     | -31.8    |
| time/              |          |
|    episodes        | 280      |
|    fps             | 84       |
|    time_elapsed    | 1637     |
|    total_timesteps | 137947   |
| train/             |          |
|    actor_loss      | 3.08     |
|    critic_loss     | 0.54     |
|    learning_rate   | 0.001    |
|    n_updates       | 127946   |
---------------------------------
Eval num_timesteps=140000, episode_reward=252.28 +/- 2.55
Episode length: 1521.80 +/- 46.46
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.52e+03 |
|    mean_reward     | 252      |
| time/              |          |
|    total_timesteps | 140000   |
| train/             |          |
|    actor_loss      | 4.15     |
|    critic_loss     | 0.396    |
|    learning_rate   | 0.001    |
|    n_updates       | 129999   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 999      |
|    ep_rew_mean     | -17.1    |
| time/              |          |
|    episodes        | 284      |
|    fps             | 82       |
|    time_elapsed    | 1742     |
|    total_timesteps | 144536   |
| train/             |          |
|    actor_loss      | 2.22     |
|    critic_loss     | 0.364    |
|    learning_rate   | 0.001    |
|    n_updates       | 134535   |
---------------------------------
Eval num_timesteps=150000, episode_reward=268.53 +/- 7.90
Episode length: 1595.00 +/- 10.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.6e+03  |
|    mean_reward     | 269      |
| time/              |          |
|    total_timesteps | 150000   |
| train/             |          |
|    actor_loss      | 2.4      |
|    critic_loss     | 0.54     |
|    learning_rate   | 0.001    |
|    n_updates       | 139999   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.04e+03 |
|    ep_rew_mean     | -3.44    |
| time/              |          |
|    episodes        | 288      |
|    fps             | 82       |
|    time_elapsed    | 1845     |
|    total_timesteps | 151353   |
| train/             |          |
|    actor_loss      | 0.178    |
|    critic_loss     | 0.571    |
|    learning_rate   | 0.001    |
|    n_updates       | 141352   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.05e+03 |
|    ep_rew_mean     | 9.57     |
| time/              |          |
|    episodes        | 292      |
|    fps             | 81       |
|    time_elapsed    | 1940     |
|    total_timesteps | 157753   |
| train/             |          |
|    actor_loss      | 3.82     |
|    critic_loss     | 1.3      |
|    learning_rate   | 0.001    |
|    n_updates       | 147752   |
---------------------------------
Eval num_timesteps=160000, episode_reward=275.08 +/- 1.36
Episode length: 1467.20 +/- 20.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.47e+03 |
|    mean_reward     | 275      |
| time/              |          |
|    total_timesteps | 160000   |
| train/             |          |
|    actor_loss      | 2.11     |
|    critic_loss     | 0.478    |
|    learning_rate   | 0.001    |
|    n_updates       | 149999   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.05e+03 |
|    ep_rew_mean     | 20.3     |
| time/              |          |
|    episodes        | 296      |
|    fps             | 80       |
|    time_elapsed    | 2015     |
|    total_timesteps | 162459   |
| train/             |          |
|    actor_loss      | -1.89    |
|    critic_loss     | 0.116    |
|    learning_rate   | 0.001    |
|    n_updates       | 152458   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.06e+03 |
|    ep_rew_mean     | 29.3     |
| time/              |          |
|    episodes        | 300      |
|    fps             | 80       |
|    time_elapsed    | 2061     |
|    total_timesteps | 165411   |
| train/             |          |
|    actor_loss      | -1.45    |
|    critic_loss     | 0.275    |
|    learning_rate   | 0.001    |
|    n_updates       | 155410   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.08e+03 |
|    ep_rew_mean     | 39.4     |
| time/              |          |
|    episodes        | 304      |
|    fps             | 79       |
|    time_elapsed    | 2115     |
|    total_timesteps | 169048   |
| train/             |          |
|    actor_loss      | -0.504   |
|    critic_loss     | 0.836    |
|    learning_rate   | 0.001    |
|    n_updates       | 159047   |
---------------------------------
Eval num_timesteps=170000, episode_reward=274.68 +/- 0.65
Episode length: 1133.20 +/- 17.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.13e+03 |
|    mean_reward     | 275      |
| time/              |          |
|    total_timesteps | 170000   |
| train/             |          |
|    actor_loss      | -2.28    |
|    critic_loss     | 0.38     |
|    learning_rate   | 0.001    |
|    n_updates       | 159999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.09e+03 |
|    ep_rew_mean     | 49.7     |
| time/              |          |
|    episodes        | 308      |
|    fps             | 79       |
|    time_elapsed    | 2177     |
|    total_timesteps | 172851   |
| train/             |          |
|    actor_loss      | 0.606    |
|    critic_loss     | 0.86     |
|    learning_rate   | 0.001    |
|    n_updates       | 162850   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.13e+03 |
|    ep_rew_mean     | 64.8     |
| time/              |          |
|    episodes        | 312      |
|    fps             | 78       |
|    time_elapsed    | 2249     |
|    total_timesteps | 177743   |
| train/             |          |
|    actor_loss      | -0.267   |
|    critic_loss     | 0.668    |
|    learning_rate   | 0.001    |
|    n_updates       | 167742   |
---------------------------------
Eval num_timesteps=180000, episode_reward=237.17 +/- 48.68
Episode length: 1392.00 +/- 59.87
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.39e+03 |
|    mean_reward     | 237      |
| time/              |          |
|    total_timesteps | 180000   |
| train/             |          |
|    actor_loss      | -0.811   |
|    critic_loss     | 0.762    |
|    learning_rate   | 0.001    |
|    n_updates       | 169999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.13e+03 |
|    ep_rew_mean     | 74.3     |
| time/              |          |
|    episodes        | 316      |
|    fps             | 78       |
|    time_elapsed    | 2322     |
|    total_timesteps | 182267   |
| train/             |          |
|    actor_loss      | 1.51     |
|    critic_loss     | 0.436    |
|    learning_rate   | 0.001    |
|    n_updates       | 172266   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.15e+03 |
|    ep_rew_mean     | 83       |
| time/              |          |
|    episodes        | 320      |
|    fps             | 78       |
|    time_elapsed    | 2370     |
|    total_timesteps | 185312   |
| train/             |          |
|    actor_loss      | -2.29    |
|    critic_loss     | 0.461    |
|    learning_rate   | 0.001    |
|    n_updates       | 175311   |
---------------------------------
Eval num_timesteps=190000, episode_reward=282.59 +/- 0.72
Episode length: 1202.00 +/- 11.08
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.2e+03  |
|    mean_reward     | 283      |
| time/              |          |
|    total_timesteps | 190000   |
| train/             |          |
|    actor_loss      | 0.945    |
|    critic_loss     | 0.701    |
|    learning_rate   | 0.001    |
|    n_updates       | 179999   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.15e+03 |
|    ep_rew_mean     | 97.4     |
| time/              |          |
|    episodes        | 324      |
|    fps             | 77       |
|    time_elapsed    | 2462     |
|    total_timesteps | 191229   |
| train/             |          |
|    actor_loss      | -1.62    |
|    critic_loss     | 0.859    |
|    learning_rate   | 0.001    |
|    n_updates       | 181228   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.17e+03 |
|    ep_rew_mean     | 112      |
| time/              |          |
|    episodes        | 328      |
|    fps             | 77       |
|    time_elapsed    | 2533     |
|    total_timesteps | 195939   |
| train/             |          |
|    actor_loss      | -3.66    |
|    critic_loss     | 0.295    |
|    learning_rate   | 0.001    |
|    n_updates       | 185938   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.17e+03 |
|    ep_rew_mean     | 123      |
| time/              |          |
|    episodes        | 332      |
|    fps             | 77       |
|    time_elapsed    | 2593     |
|    total_timesteps | 199790   |
| train/             |          |
|    actor_loss      | -2.38    |
|    critic_loss     | 1.89     |
|    learning_rate   | 0.001    |
|    n_updates       | 189789   |
---------------------------------
Eval num_timesteps=200000, episode_reward=282.35 +/- 1.56
Episode length: 1116.80 +/- 18.63
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.12e+03 |
|    mean_reward     | 282      |
| time/              |          |
|    total_timesteps | 200000   |
| train/             |          |
|    actor_loss      | -2.72    |
|    critic_loss     | 1.71     |
|    learning_rate   | 0.001    |
|    n_updates       | 189999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.2e+03  |
|    ep_rew_mean     | 137      |
| time/              |          |
|    episodes        | 336      |
|    fps             | 76       |
|    time_elapsed    | 2666     |
|    total_timesteps | 204268   |
| train/             |          |
|    actor_loss      | -3.19    |
|    critic_loss     | 1.65     |
|    learning_rate   | 0.001    |
|    n_updates       | 194267   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.23e+03 |
|    ep_rew_mean     | 150      |
| time/              |          |
|    episodes        | 340      |
|    fps             | 76       |
|    time_elapsed    | 2730     |
|    total_timesteps | 208573   |
| train/             |          |
|    actor_loss      | -1.63    |
|    critic_loss     | 1.96     |
|    learning_rate   | 0.001    |
|    n_updates       | 198572   |
---------------------------------
Eval num_timesteps=210000, episode_reward=275.53 +/- 1.46
Episode length: 1078.00 +/- 43.06
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.08e+03 |
|    mean_reward     | 276      |
| time/              |          |
|    total_timesteps | 210000   |
| train/             |          |
|    actor_loss      | -1.5     |
|    critic_loss     | 0.367    |
|    learning_rate   | 0.001    |
|    n_updates       | 199999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.21e+03 |
|    ep_rew_mean     | 153      |
| time/              |          |
|    episodes        | 344      |
|    fps             | 76       |
|    time_elapsed    | 2781     |
|    total_timesteps | 211525   |
| train/             |          |
|    actor_loss      | -5.5     |
|    critic_loss     | 0.347    |
|    learning_rate   | 0.001    |
|    n_updates       | 201524   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.19e+03 |
|    ep_rew_mean     | 163      |
| time/              |          |
|    episodes        | 348      |
|    fps             | 75       |
|    time_elapsed    | 2847     |
|    total_timesteps | 215855   |
| train/             |          |
|    actor_loss      | -5.06    |
|    critic_loss     | 0.299    |
|    learning_rate   | 0.001    |
|    n_updates       | 205854   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.19e+03 |
|    ep_rew_mean     | 174      |
| time/              |          |
|    episodes        | 352      |
|    fps             | 75       |
|    time_elapsed    | 2908     |
|    total_timesteps | 219871   |
| train/             |          |
|    actor_loss      | -3.36    |
|    critic_loss     | 0.386    |
|    learning_rate   | 0.001    |
|    n_updates       | 209870   |
---------------------------------
Eval num_timesteps=220000, episode_reward=287.28 +/- 0.39
Episode length: 1049.00 +/- 8.17
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.05e+03 |
|    mean_reward     | 287      |
| time/              |          |
|    total_timesteps | 220000   |
| train/             |          |
|    actor_loss      | -4.48    |
|    critic_loss     | 0.367    |
|    learning_rate   | 0.001    |
|    n_updates       | 209999   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.17e+03 |
|    ep_rew_mean     | 180      |
| time/              |          |
|    episodes        | 356      |
|    fps             | 75       |
|    time_elapsed    | 2970     |
|    total_timesteps | 223667   |
| train/             |          |
|    actor_loss      | -4.46    |
|    critic_loss     | 0.69     |
|    learning_rate   | 0.001    |
|    n_updates       | 213666   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.14e+03 |
|    ep_rew_mean     | 188      |
| time/              |          |
|    episodes        | 360      |
|    fps             | 74       |
|    time_elapsed    | 3038     |
|    total_timesteps | 227829   |
| train/             |          |
|    actor_loss      | -6       |
|    critic_loss     | 0.348    |
|    learning_rate   | 0.001    |
|    n_updates       | 217828   |
---------------------------------
Eval num_timesteps=230000, episode_reward=291.46 +/- 0.62
Episode length: 950.60 +/- 12.27
---------------------------------
| eval/              |          |
|    mean_ep_length  | 951      |
|    mean_reward     | 291      |
| time/              |          |
|    total_timesteps | 230000   |
| train/             |          |
|    actor_loss      | -5.9     |
|    critic_loss     | 0.306    |
|    learning_rate   | 0.001    |
|    n_updates       | 219999   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.12e+03 |
|    ep_rew_mean     | 194      |
| time/              |          |
|    episodes        | 364      |
|    fps             | 74       |
|    time_elapsed    | 3106     |
|    total_timesteps | 231987   |
| train/             |          |
|    actor_loss      | -6.53    |
|    critic_loss     | 0.263    |
|    learning_rate   | 0.001    |
|    n_updates       | 221986   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.1e+03  |
|    ep_rew_mean     | 200      |
| time/              |          |
|    episodes        | 368      |
|    fps             | 74       |
|    time_elapsed    | 3170     |
|    total_timesteps | 236048   |
| train/             |          |
|    actor_loss      | -7.94    |
|    critic_loss     | 0.23     |
|    learning_rate   | 0.001    |
|    n_updates       | 226047   |
---------------------------------
Eval num_timesteps=240000, episode_reward=210.56 +/- 158.54
Episode length: 806.20 +/- 348.25
---------------------------------
| eval/              |          |
|    mean_ep_length  | 806      |
|    mean_reward     | 211      |
| time/              |          |
|    total_timesteps | 240000   |
| train/             |          |
|    actor_loss      | -7.01    |
|    critic_loss     | 0.279    |
|    learning_rate   | 0.001    |
|    n_updates       | 229999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.09e+03 |
|    ep_rew_mean     | 210      |
| time/              |          |
|    episodes        | 372      |
|    fps             | 74       |
|    time_elapsed    | 3238     |
|    total_timesteps | 240000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.06e+03 |
|    ep_rew_mean     | 214      |
| time/              |          |
|    episodes        | 376      |
|    fps             | 73       |
|    time_elapsed    | 3285     |
|    total_timesteps | 242987   |
| train/             |          |
|    actor_loss      | -6.96    |
|    critic_loss     | 1.4      |
|    learning_rate   | 0.001    |
|    n_updates       | 232986   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.04e+03 |
|    ep_rew_mean     | 216      |
| time/              |          |
|    episodes        | 380      |
|    fps             | 73       |
|    time_elapsed    | 3348     |
|    total_timesteps | 247001   |
| train/             |          |
|    actor_loss      | -7.91    |
|    critic_loss     | 0.137    |
|    learning_rate   | 0.001    |
|    n_updates       | 237000   |
---------------------------------
Eval num_timesteps=250000, episode_reward=283.33 +/- 0.89
Episode length: 1001.80 +/- 5.27
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 283      |
| time/              |          |
|    total_timesteps | 250000   |
| train/             |          |
|    actor_loss      | -9.51    |
|    critic_loss     | 0.13     |
|    learning_rate   | 0.001    |
|    n_updates       | 239999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.02e+03 |
|    ep_rew_mean     | 217      |
| time/              |          |
|    episodes        | 384      |
|    fps             | 73       |
|    time_elapsed    | 3415     |
|    total_timesteps | 250995   |
| train/             |          |
|    actor_loss      | -8.57    |
|    critic_loss     | 0.239    |
|    learning_rate   | 0.001    |
|    n_updates       | 240994   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 993      |
|    ep_rew_mean     | 218      |
| time/              |          |
|    episodes        | 388      |
|    fps             | 73       |
|    time_elapsed    | 3472     |
|    total_timesteps | 254708   |
| train/             |          |
|    actor_loss      | -9.24    |
|    critic_loss     | 0.947    |
|    learning_rate   | 0.001    |
|    n_updates       | 244707   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 968      |
|    ep_rew_mean     | 221      |
| time/              |          |
|    episodes        | 392      |
|    fps             | 73       |
|    time_elapsed    | 3533     |
|    total_timesteps | 258593   |
| train/             |          |
|    actor_loss      | -8.28    |
|    critic_loss     | 0.41     |
|    learning_rate   | 0.001    |
|    n_updates       | 248592   |
---------------------------------
Eval num_timesteps=260000, episode_reward=283.26 +/- 0.28
Episode length: 1013.20 +/- 6.11
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.01e+03 |
|    mean_reward     | 283      |
| time/              |          |
|    total_timesteps | 260000   |
| train/             |          |
|    actor_loss      | -9.8     |
|    critic_loss     | 4.23     |
|    learning_rate   | 0.001    |
|    n_updates       | 249999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 965      |
|    ep_rew_mean     | 227      |
| time/              |          |
|    episodes        | 396      |
|    fps             | 72       |
|    time_elapsed    | 3602     |
|    total_timesteps | 262868   |
| train/             |          |
|    actor_loss      | -10.1    |
|    critic_loss     | 0.386    |
|    learning_rate   | 0.001    |
|    n_updates       | 252867   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 973      |
|    ep_rew_mean     | 235      |
| time/              |          |
|    episodes        | 400      |
|    fps             | 72       |
|    time_elapsed    | 3663     |
|    total_timesteps | 266692   |
| train/             |          |
|    actor_loss      | -10.1    |
|    critic_loss     | 0.0506   |
|    learning_rate   | 0.001    |
|    n_updates       | 256691   |
---------------------------------
Eval num_timesteps=270000, episode_reward=262.46 +/- 70.50
Episode length: 885.00 +/- 72.19
---------------------------------
| eval/              |          |
|    mean_ep_length  | 885      |
|    mean_reward     | 262      |
| time/              |          |
|    total_timesteps | 270000   |
| train/             |          |
|    actor_loss      | -8.57    |
|    critic_loss     | 0.29     |
|    learning_rate   | 0.001    |
|    n_updates       | 259999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 970      |
|    ep_rew_mean     | 238      |
| time/              |          |
|    episodes        | 404      |
|    fps             | 72       |
|    time_elapsed    | 3735     |
|    total_timesteps | 270894   |
| train/             |          |
|    actor_loss      | -10.6    |
|    critic_loss     | 0.109    |
|    learning_rate   | 0.001    |
|    n_updates       | 260893   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 970      |
|    ep_rew_mean     | 244      |
| time/              |          |
|    episodes        | 408      |
|    fps             | 72       |
|    time_elapsed    | 3796     |
|    total_timesteps | 274475   |
| train/             |          |
|    actor_loss      | -10.2    |
|    critic_loss     | 0.23     |
|    learning_rate   | 0.001    |
|    n_updates       | 264474   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 958      |
|    ep_rew_mean     | 245      |
| time/              |          |
|    episodes        | 412      |
|    fps             | 72       |
|    time_elapsed    | 3853     |
|    total_timesteps | 278109   |
| train/             |          |
|    actor_loss      | -11.5    |
|    critic_loss     | 0.154    |
|    learning_rate   | 0.001    |
|    n_updates       | 268108   |
---------------------------------
Eval num_timesteps=280000, episode_reward=298.00 +/- 0.75
Episode length: 921.80 +/- 8.28
---------------------------------
| eval/              |          |
|    mean_ep_length  | 922      |
|    mean_reward     | 298      |
| time/              |          |
|    total_timesteps | 280000   |
| train/             |          |
|    actor_loss      | -11.7    |
|    critic_loss     | 0.447    |
|    learning_rate   | 0.001    |
|    n_updates       | 269999   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 958      |
|    ep_rew_mean     | 252      |
| time/              |          |
|    episodes        | 416      |
|    fps             | 71       |
|    time_elapsed    | 3914     |
|    total_timesteps | 281820   |
| train/             |          |
|    actor_loss      | -10.7    |
|    critic_loss     | 0.249    |
|    learning_rate   | 0.001    |
|    n_updates       | 271819   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 956      |
|    ep_rew_mean     | 255      |
| time/              |          |
|    episodes        | 420      |
|    fps             | 71       |
|    time_elapsed    | 3960     |
|    total_timesteps | 284607   |
| train/             |          |
|    actor_loss      | -12      |
|    critic_loss     | 0.0819   |
|    learning_rate   | 0.001    |
|    n_updates       | 274606   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 941      |
|    ep_rew_mean     | 256      |
| time/              |          |
|    episodes        | 424      |
|    fps             | 71       |
|    time_elapsed    | 4018     |
|    total_timesteps | 288101   |
| train/             |          |
|    actor_loss      | -11.7    |
|    critic_loss     | 0.124    |
|    learning_rate   | 0.001    |
|    n_updates       | 278100   |
---------------------------------
Eval num_timesteps=290000, episode_reward=252.25 +/- 97.03
Episode length: 775.20 +/- 148.61
---------------------------------
| eval/              |          |
|    mean_ep_length  | 775      |
|    mean_reward     | 252      |
| time/              |          |
|    total_timesteps | 290000   |
| train/             |          |
|    actor_loss      | -10.2    |
|    critic_loss     | 0.104    |
|    learning_rate   | 0.001    |
|    n_updates       | 279999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 929      |
|    ep_rew_mean     | 257      |
| time/              |          |
|    episodes        | 428      |
|    fps             | 71       |
|    time_elapsed    | 4079     |
|    total_timesteps | 291732   |
| train/             |          |
|    actor_loss      | -11.6    |
|    critic_loss     | 0.353    |
|    learning_rate   | 0.001    |
|    n_updates       | 281731   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 919      |
|    ep_rew_mean     | 258      |
| time/              |          |
|    episodes        | 432      |
|    fps             | 71       |
|    time_elapsed    | 4127     |
|    total_timesteps | 294601   |
| train/             |          |
|    actor_loss      | -12.2    |
|    critic_loss     | 0.094    |
|    learning_rate   | 0.001    |
|    n_updates       | 284600   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 911      |
|    ep_rew_mean     | 261      |
| time/              |          |
|    episodes        | 436      |
|    fps             | 71       |
|    time_elapsed    | 4186     |
|    total_timesteps | 298056   |
| train/             |          |
|    actor_loss      | -13.1    |
|    critic_loss     | 0.569    |
|    learning_rate   | 0.001    |
|    n_updates       | 288055   |
---------------------------------
Eval num_timesteps=300000, episode_reward=302.13 +/- 1.12
Episode length: 849.40 +/- 7.53
---------------------------------
| eval/              |          |
|    mean_ep_length  | 849      |
|    mean_reward     | 302      |
| time/              |          |
|    total_timesteps | 300000   |
| train/             |          |
|    actor_loss      | -12.6    |
|    critic_loss     | 4.16     |
|    learning_rate   | 0.001    |
|    n_updates       | 289999   |
---------------------------------
New best mean reward!
Stopping training because the mean reward 302.13  is above the threshold 300
Training complete. Model saved.
Plotting sample efficiency...
Evaluating model...
mean_reward:282.66 +/- 75.55
