=== Training with seed: 2024 ===
Using cpu device
Training td3 on BipedalWalker-v3...
Logging to ./tensorboard/td3_BipedalWalker-v3_seed2024/TD3_1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 831      |
|    ep_rew_mean     | -97.3    |
| time/              |          |
|    episodes        | 4        |
|    fps             | 3339     |
|    time_elapsed    | 0        |
|    total_timesteps | 3323     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 648      |
|    ep_rew_mean     | -99.4    |
| time/              |          |
|    episodes        | 8        |
|    fps             | 3357     |
|    time_elapsed    | 1        |
|    total_timesteps | 5188     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 708      |
|    ep_rew_mean     | -98.9    |
| time/              |          |
|    episodes        | 12       |
|    fps             | 3370     |
|    time_elapsed    | 2        |
|    total_timesteps | 8500     |
---------------------------------
Eval num_timesteps=10000, episode_reward=-92.04 +/- 0.05
Episode length: 107.80 +/- 0.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 108      |
|    mean_reward     | -92      |
| time/              |          |
|    total_timesteps | 10000    |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 568      |
|    ep_rew_mean     | -104     |
| time/              |          |
|    episodes        | 16       |
|    fps             | 1396     |
|    time_elapsed    | 7        |
|    total_timesteps | 10582    |
| train/             |          |
|    actor_loss      | 0.253    |
|    critic_loss     | 1.8      |
|    learning_rate   | 0.001    |
|    n_updates       | 581      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 477      |
|    ep_rew_mean     | -108     |
| time/              |          |
|    episodes        | 20       |
|    fps             | 909      |
|    time_elapsed    | 12       |
|    total_timesteps | 11038    |
| train/             |          |
|    actor_loss      | 0.14     |
|    critic_loss     | 1.35     |
|    learning_rate   | 0.001    |
|    n_updates       | 1037     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 453      |
|    ep_rew_mean     | -109     |
| time/              |          |
|    episodes        | 24       |
|    fps             | 439      |
|    time_elapsed    | 28       |
|    total_timesteps | 12370    |
| train/             |          |
|    actor_loss      | -0.418   |
|    critic_loss     | 0.129    |
|    learning_rate   | 0.001    |
|    n_updates       | 2369     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 453      |
|    ep_rew_mean     | -109     |
| time/              |          |
|    episodes        | 28       |
|    fps             | 277      |
|    time_elapsed    | 51       |
|    total_timesteps | 14174    |
| train/             |          |
|    actor_loss      | -0.772   |
|    critic_loss     | 0.148    |
|    learning_rate   | 0.001    |
|    n_updates       | 4173     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 431      |
|    ep_rew_mean     | -111     |
| time/              |          |
|    episodes        | 32       |
|    fps             | 233      |
|    time_elapsed    | 65       |
|    total_timesteps | 15295    |
| train/             |          |
|    actor_loss      | -0.486   |
|    critic_loss     | 0.289    |
|    learning_rate   | 0.001    |
|    n_updates       | 5294     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 474      |
|    ep_rew_mean     | -114     |
| time/              |          |
|    episodes        | 36       |
|    fps             | 171      |
|    time_elapsed    | 108      |
|    total_timesteps | 18563    |
| train/             |          |
|    actor_loss      | 0.455    |
|    critic_loss     | 68.6     |
|    learning_rate   | 0.001    |
|    n_updates       | 8562     |
---------------------------------
Eval num_timesteps=20000, episode_reward=-71.96 +/- 2.29
Episode length: 1600.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.6e+03  |
|    mean_reward     | -72      |
| time/              |          |
|    total_timesteps | 20000    |
| train/             |          |
|    actor_loss      | 0.195    |
|    critic_loss     | 0.316    |
|    learning_rate   | 0.001    |
|    n_updates       | 9999     |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 521      |
|    ep_rew_mean     | -117     |
| time/              |          |
|    episodes        | 40       |
|    fps             | 134      |
|    time_elapsed    | 170      |
|    total_timesteps | 22826    |
| train/             |          |
|    actor_loss      | -0.331   |
|    critic_loss     | 0.28     |
|    learning_rate   | 0.001    |
|    n_updates       | 12825    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 482      |
|    ep_rew_mean     | -115     |
| time/              |          |
|    episodes        | 44       |
|    fps             | 132      |
|    time_elapsed    | 174      |
|    total_timesteps | 23186    |
| train/             |          |
|    actor_loss      | 0.432    |
|    critic_loss     | 8.95     |
|    learning_rate   | 0.001    |
|    n_updates       | 13185    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 482      |
|    ep_rew_mean     | -114     |
| time/              |          |
|    episodes        | 48       |
|    fps             | 125      |
|    time_elapsed    | 200      |
|    total_timesteps | 25125    |
| train/             |          |
|    actor_loss      | 0.643    |
|    critic_loss     | 1.28     |
|    learning_rate   | 0.001    |
|    n_updates       | 15124    |
---------------------------------
Eval num_timesteps=30000, episode_reward=-90.21 +/- 4.53
Episode length: 1600.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.6e+03  |
|    mean_reward     | -90.2    |
| time/              |          |
|    total_timesteps | 30000    |
| train/             |          |
|    actor_loss      | 2.38     |
|    critic_loss     | 2.4      |
|    learning_rate   | 0.001    |
|    n_updates       | 19999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 538      |
|    ep_rew_mean     | -113     |
| time/              |          |
|    episodes        | 52       |
|    fps             | 109      |
|    time_elapsed    | 274      |
|    total_timesteps | 30039    |
| train/             |          |
|    actor_loss      | 0.198    |
|    critic_loss     | 0.714    |
|    learning_rate   | 0.001    |
|    n_updates       | 20038    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 535      |
|    ep_rew_mean     | -114     |
| time/              |          |
|    episodes        | 56       |
|    fps             | 106      |
|    time_elapsed    | 300      |
|    total_timesteps | 32019    |
| train/             |          |
|    actor_loss      | 0.547    |
|    critic_loss     | 0.277    |
|    learning_rate   | 0.001    |
|    n_updates       | 22018    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 506      |
|    ep_rew_mean     | -114     |
| time/              |          |
|    episodes        | 60       |
|    fps             | 105      |
|    time_elapsed    | 306      |
|    total_timesteps | 32417    |
| train/             |          |
|    actor_loss      | 2.23     |
|    critic_loss     | 0.787    |
|    learning_rate   | 0.001    |
|    n_updates       | 22416    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 508      |
|    ep_rew_mean     | -114     |
| time/              |          |
|    episodes        | 64       |
|    fps             | 102      |
|    time_elapsed    | 335      |
|    total_timesteps | 34550    |
| train/             |          |
|    actor_loss      | 1.96     |
|    critic_loss     | 0.267    |
|    learning_rate   | 0.001    |
|    n_updates       | 24549    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 506      |
|    ep_rew_mean     | -114     |
| time/              |          |
|    episodes        | 68       |
|    fps             | 100      |
|    time_elapsed    | 361      |
|    total_timesteps | 36451    |
| train/             |          |
|    actor_loss      | 3.09     |
|    critic_loss     | 2.17     |
|    learning_rate   | 0.001    |
|    n_updates       | 26450    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 484      |
|    ep_rew_mean     | -115     |
| time/              |          |
|    episodes        | 72       |
|    fps             | 100      |
|    time_elapsed    | 367      |
|    total_timesteps | 36887    |
| train/             |          |
|    actor_loss      | 2.91     |
|    critic_loss     | 0.491    |
|    learning_rate   | 0.001    |
|    n_updates       | 26886    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 462      |
|    ep_rew_mean     | -115     |
| time/              |          |
|    episodes        | 76       |
|    fps             | 100      |
|    time_elapsed    | 370      |
|    total_timesteps | 37134    |
| train/             |          |
|    actor_loss      | 5.23     |
|    critic_loss     | 0.755    |
|    learning_rate   | 0.001    |
|    n_updates       | 27133    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 441      |
|    ep_rew_mean     | -114     |
| time/              |          |
|    episodes        | 80       |
|    fps             | 100      |
|    time_elapsed    | 373      |
|    total_timesteps | 37349    |
| train/             |          |
|    actor_loss      | 2.04     |
|    critic_loss     | 0.309    |
|    learning_rate   | 0.001    |
|    n_updates       | 27348    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 423      |
|    ep_rew_mean     | -113     |
| time/              |          |
|    episodes        | 84       |
|    fps             | 99       |
|    time_elapsed    | 376      |
|    total_timesteps | 37604    |
| train/             |          |
|    actor_loss      | 0.581    |
|    critic_loss     | 0.84     |
|    learning_rate   | 0.001    |
|    n_updates       | 27603    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 407      |
|    ep_rew_mean     | -113     |
| time/              |          |
|    episodes        | 88       |
|    fps             | 99       |
|    time_elapsed    | 380      |
|    total_timesteps | 37861    |
| train/             |          |
|    actor_loss      | 3.54     |
|    critic_loss     | 1.04     |
|    learning_rate   | 0.001    |
|    n_updates       | 27860    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 392      |
|    ep_rew_mean     | -113     |
| time/              |          |
|    episodes        | 92       |
|    fps             | 99       |
|    time_elapsed    | 383      |
|    total_timesteps | 38079    |
| train/             |          |
|    actor_loss      | 2.6      |
|    critic_loss     | 1.09     |
|    learning_rate   | 0.001    |
|    n_updates       | 28078    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 379      |
|    ep_rew_mean     | -112     |
| time/              |          |
|    episodes        | 96       |
|    fps             | 99       |
|    time_elapsed    | 387      |
|    total_timesteps | 38395    |
| train/             |          |
|    actor_loss      | 5.94     |
|    critic_loss     | 0.531    |
|    learning_rate   | 0.001    |
|    n_updates       | 28394    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 366      |
|    ep_rew_mean     | -112     |
| time/              |          |
|    episodes        | 100      |
|    fps             | 98       |
|    time_elapsed    | 390      |
|    total_timesteps | 38627    |
| train/             |          |
|    actor_loss      | 2.97     |
|    critic_loss     | 1.19     |
|    learning_rate   | 0.001    |
|    n_updates       | 28626    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 335      |
|    ep_rew_mean     | -112     |
| time/              |          |
|    episodes        | 104      |
|    fps             | 98       |
|    time_elapsed    | 393      |
|    total_timesteps | 38833    |
| train/             |          |
|    actor_loss      | 2.64     |
|    critic_loss     | 0.986    |
|    learning_rate   | 0.001    |
|    n_updates       | 28832    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 319      |
|    ep_rew_mean     | -112     |
| time/              |          |
|    episodes        | 108      |
|    fps             | 98       |
|    time_elapsed    | 397      |
|    total_timesteps | 39089    |
| train/             |          |
|    actor_loss      | 4.3      |
|    critic_loss     | 57.4     |
|    learning_rate   | 0.001    |
|    n_updates       | 29088    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 288      |
|    ep_rew_mean     | -113     |
| time/              |          |
|    episodes        | 112      |
|    fps             | 98       |
|    time_elapsed    | 400      |
|    total_timesteps | 39336    |
| train/             |          |
|    actor_loss      | 3.06     |
|    critic_loss     | 1.09     |
|    learning_rate   | 0.001    |
|    n_updates       | 29335    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 285      |
|    ep_rew_mean     | -112     |
| time/              |          |
|    episodes        | 116      |
|    fps             | 97       |
|    time_elapsed    | 405      |
|    total_timesteps | 39665    |
| train/             |          |
|    actor_loss      | 1.18     |
|    critic_loss     | 0.448    |
|    learning_rate   | 0.001    |
|    n_updates       | 29664    |
---------------------------------
Eval num_timesteps=40000, episode_reward=-110.36 +/- 2.24
Episode length: 83.00 +/- 7.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 83       |
|    mean_reward     | -110     |
| time/              |          |
|    total_timesteps | 40000    |
| train/             |          |
|    actor_loss      | 6.23     |
|    critic_loss     | 0.336    |
|    learning_rate   | 0.001    |
|    n_updates       | 29999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 283      |
|    ep_rew_mean     | -111     |
| time/              |          |
|    episodes        | 120      |
|    fps             | 97       |
|    time_elapsed    | 411      |
|    total_timesteps | 40065    |
| train/             |          |
|    actor_loss      | 4.46     |
|    critic_loss     | 1.57     |
|    learning_rate   | 0.001    |
|    n_updates       | 30064    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 273      |
|    ep_rew_mean     | -111     |
| time/              |          |
|    episodes        | 124      |
|    fps             | 97       |
|    time_elapsed    | 415      |
|    total_timesteps | 40367    |
| train/             |          |
|    actor_loss      | 5.34     |
|    critic_loss     | 1.64     |
|    learning_rate   | 0.001    |
|    n_updates       | 30366    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 258      |
|    ep_rew_mean     | -111     |
| time/              |          |
|    episodes        | 128      |
|    fps             | 97       |
|    time_elapsed    | 419      |
|    total_timesteps | 40676    |
| train/             |          |
|    actor_loss      | 6.55     |
|    critic_loss     | 1.44     |
|    learning_rate   | 0.001    |
|    n_updates       | 30675    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -110     |
| time/              |          |
|    episodes        | 132      |
|    fps             | 96       |
|    time_elapsed    | 424      |
|    total_timesteps | 41035    |
| train/             |          |
|    actor_loss      | 3.61     |
|    critic_loss     | 1.28     |
|    learning_rate   | 0.001    |
|    n_updates       | 31034    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | -109     |
| time/              |          |
|    episodes        | 136      |
|    fps             | 96       |
|    time_elapsed    | 428      |
|    total_timesteps | 41344    |
| train/             |          |
|    actor_loss      | 4.38     |
|    critic_loss     | 1.28     |
|    learning_rate   | 0.001    |
|    n_updates       | 31343    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 187      |
|    ep_rew_mean     | -107     |
| time/              |          |
|    episodes        | 140      |
|    fps             | 96       |
|    time_elapsed    | 433      |
|    total_timesteps | 41734    |
| train/             |          |
|    actor_loss      | 4.47     |
|    critic_loss     | 1.85     |
|    learning_rate   | 0.001    |
|    n_updates       | 31733    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 188      |
|    ep_rew_mean     | -108     |
| time/              |          |
|    episodes        | 144      |
|    fps             | 95       |
|    time_elapsed    | 439      |
|    total_timesteps | 42167    |
| train/             |          |
|    actor_loss      | 5.13     |
|    critic_loss     | 0.905    |
|    learning_rate   | 0.001    |
|    n_updates       | 32166    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 171      |
|    ep_rew_mean     | -108     |
| time/              |          |
|    episodes        | 148      |
|    fps             | 95       |
|    time_elapsed    | 443      |
|    total_timesteps | 42468    |
| train/             |          |
|    actor_loss      | 8.89     |
|    critic_loss     | 1.12     |
|    learning_rate   | 0.001    |
|    n_updates       | 32467    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 165      |
|    ep_rew_mean     | -110     |
| time/              |          |
|    episodes        | 152      |
|    fps             | 93       |
|    time_elapsed    | 501      |
|    total_timesteps | 46661    |
| train/             |          |
|    actor_loss      | 2.9      |
|    critic_loss     | 0.608    |
|    learning_rate   | 0.001    |
|    n_updates       | 36660    |
---------------------------------
Eval num_timesteps=50000, episode_reward=-83.55 +/- 6.87
Episode length: 1600.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.6e+03  |
|    mean_reward     | -83.5    |
| time/              |          |
|    total_timesteps | 50000    |
| train/             |          |
|    actor_loss      | 5.91     |
|    critic_loss     | 1.42     |
|    learning_rate   | 0.001    |
|    n_updates       | 39999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 191      |
|    ep_rew_mean     | -110     |
| time/              |          |
|    episodes        | 156      |
|    fps             | 89       |
|    time_elapsed    | 573      |
|    total_timesteps | 51419    |
| train/             |          |
|    actor_loss      | 6.65     |
|    critic_loss     | 0.902    |
|    learning_rate   | 0.001    |
|    n_updates       | 41418    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 198      |
|    ep_rew_mean     | -109     |
| time/              |          |
|    episodes        | 160      |
|    fps             | 89       |
|    time_elapsed    | 587      |
|    total_timesteps | 52455    |
| train/             |          |
|    actor_loss      | 3.74     |
|    critic_loss     | 1.62     |
|    learning_rate   | 0.001    |
|    n_updates       | 42454    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 199      |
|    ep_rew_mean     | -110     |
| time/              |          |
|    episodes        | 164      |
|    fps             | 88       |
|    time_elapsed    | 618      |
|    total_timesteps | 54673    |
| train/             |          |
|    actor_loss      | 7.55     |
|    critic_loss     | 4.13     |
|    learning_rate   | 0.001    |
|    n_updates       | 44672    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 232      |
|    ep_rew_mean     | -110     |
| time/              |          |
|    episodes        | 168      |
|    fps             | 86       |
|    time_elapsed    | 695      |
|    total_timesteps | 59926    |
| train/             |          |
|    actor_loss      | 5.25     |
|    critic_loss     | 0.82     |
|    learning_rate   | 0.001    |
|    n_updates       | 49925    |
---------------------------------
Eval num_timesteps=60000, episode_reward=-119.66 +/- 3.66
Episode length: 1600.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.6e+03  |
|    mean_reward     | -120     |
| time/              |          |
|    total_timesteps | 60000    |
| train/             |          |
|    actor_loss      | 5.81     |
|    critic_loss     | 1.19     |
|    learning_rate   | 0.001    |
|    n_updates       | 49999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 292      |
|    ep_rew_mean     | -109     |
| time/              |          |
|    episodes        | 172      |
|    fps             | 82       |
|    time_elapsed    | 802      |
|    total_timesteps | 66400    |
| train/             |          |
|    actor_loss      | 8.89     |
|    critic_loss     | 0.778    |
|    learning_rate   | 0.001    |
|    n_updates       | 56399    |
---------------------------------
Eval num_timesteps=70000, episode_reward=-53.71 +/- 5.20
Episode length: 1600.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.6e+03  |
|    mean_reward     | -53.7    |
| time/              |          |
|    total_timesteps | 70000    |
| train/             |          |
|    actor_loss      | 4.98     |
|    critic_loss     | 0.742    |
|    learning_rate   | 0.001    |
|    n_updates       | 59999    |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 353      |
|    ep_rew_mean     | -107     |
| time/              |          |
|    episodes        | 176      |
|    fps             | 80       |
|    time_elapsed    | 914      |
|    total_timesteps | 73200    |
| train/             |          |
|    actor_loss      | 7.95     |
|    critic_loss     | 1.02     |
|    learning_rate   | 0.001    |
|    n_updates       | 63199    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 415      |
|    ep_rew_mean     | -106     |
| time/              |          |
|    episodes        | 180      |
|    fps             | 78       |
|    time_elapsed    | 1014     |
|    total_timesteps | 79600    |
| train/             |          |
|    actor_loss      | 6.72     |
|    critic_loss     | 0.336    |
|    learning_rate   | 0.001    |
|    n_updates       | 69599    |
---------------------------------
Eval num_timesteps=80000, episode_reward=-54.25 +/- 0.38
Episode length: 1600.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.6e+03  |
|    mean_reward     | -54.3    |
| time/              |          |
|    total_timesteps | 80000    |
| train/             |          |
|    actor_loss      | 5.19     |
|    critic_loss     | 0.755    |
|    learning_rate   | 0.001    |
|    n_updates       | 69999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 471      |
|    ep_rew_mean     | -105     |
| time/              |          |
|    episodes        | 184      |
|    fps             | 76       |
|    time_elapsed    | 1120     |
|    total_timesteps | 85822    |
| train/             |          |
|    actor_loss      | 6.62     |
|    critic_loss     | 0.383    |
|    learning_rate   | 0.001    |
|    n_updates       | 75821    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 483      |
|    ep_rew_mean     | -105     |
| time/              |          |
|    episodes        | 188      |
|    fps             | 76       |
|    time_elapsed    | 1145     |
|    total_timesteps | 87328    |
| train/             |          |
|    actor_loss      | 6.19     |
|    critic_loss     | 0.613    |
|    learning_rate   | 0.001    |
|    n_updates       | 77327    |
---------------------------------
Eval num_timesteps=90000, episode_reward=-60.62 +/- 12.37
Episode length: 1600.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.6e+03  |
|    mean_reward     | -60.6    |
| time/              |          |
|    total_timesteps | 90000    |
| train/             |          |
|    actor_loss      | 6.15     |
|    critic_loss     | 1.3      |
|    learning_rate   | 0.001    |
|    n_updates       | 79999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 502      |
|    ep_rew_mean     | -106     |
| time/              |          |
|    episodes        | 192      |
|    fps             | 75       |
|    time_elapsed    | 1201     |
|    total_timesteps | 90447    |
| train/             |          |
|    actor_loss      | 4.21     |
|    critic_loss     | 0.115    |
|    learning_rate   | 0.001    |
|    n_updates       | 80446    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 546      |
|    ep_rew_mean     | -105     |
| time/              |          |
|    episodes        | 196      |
|    fps             | 74       |
|    time_elapsed    | 1276     |
|    total_timesteps | 95120    |
| train/             |          |
|    actor_loss      | 5.77     |
|    critic_loss     | 0.383    |
|    learning_rate   | 0.001    |
|    n_updates       | 85119    |
---------------------------------
Eval num_timesteps=100000, episode_reward=-96.21 +/- 2.91
Episode length: 1600.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.6e+03  |
|    mean_reward     | -96.2    |
| time/              |          |
|    total_timesteps | 100000   |
| train/             |          |
|    actor_loss      | 7.76     |
|    critic_loss     | 0.251    |
|    learning_rate   | 0.001    |
|    n_updates       | 89999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 608      |
|    ep_rew_mean     | -104     |
| time/              |          |
|    episodes        | 200      |
|    fps             | 73       |
|    time_elapsed    | 1390     |
|    total_timesteps | 101600   |
| train/             |          |
|    actor_loss      | 6.02     |
|    critic_loss     | 0.921    |
|    learning_rate   | 0.001    |
|    n_updates       | 91599    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 667      |
|    ep_rew_mean     | -103     |
| time/              |          |
|    episodes        | 204      |
|    fps             | 72       |
|    time_elapsed    | 1492     |
|    total_timesteps | 107721   |
| train/             |          |
|    actor_loss      | 9.2      |
|    critic_loss     | 0.946    |
|    learning_rate   | 0.001    |
|    n_updates       | 97720    |
---------------------------------
Eval num_timesteps=110000, episode_reward=-66.08 +/- 1.40
Episode length: 1600.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.6e+03  |
|    mean_reward     | -66.1    |
| time/              |          |
|    total_timesteps | 110000   |
| train/             |          |
|    actor_loss      | 5.53     |
|    critic_loss     | 1.5      |
|    learning_rate   | 0.001    |
|    n_updates       | 99999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 713      |
|    ep_rew_mean     | -101     |
| time/              |          |
|    episodes        | 208      |
|    fps             | 71       |
|    time_elapsed    | 1591     |
|    total_timesteps | 113242   |
| train/             |          |
|    actor_loss      | 8.04     |
|    critic_loss     | 0.776    |
|    learning_rate   | 0.001    |
|    n_updates       | 103241   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 756      |
|    ep_rew_mean     | -101     |
| time/              |          |
|    episodes        | 212      |
|    fps             | 70       |
|    time_elapsed    | 1669     |
|    total_timesteps | 117851   |
| train/             |          |
|    actor_loss      | 2.97     |
|    critic_loss     | 0.205    |
|    learning_rate   | 0.001    |
|    n_updates       | 107850   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 761      |
|    ep_rew_mean     | -100     |
| time/              |          |
|    episodes        | 216      |
|    fps             | 70       |
|    time_elapsed    | 1682     |
|    total_timesteps | 118621   |
| train/             |          |
|    actor_loss      | 4.58     |
|    critic_loss     | 2.58     |
|    learning_rate   | 0.001    |
|    n_updates       | 108620   |
---------------------------------
Eval num_timesteps=120000, episode_reward=-97.99 +/- 6.35
Episode length: 173.60 +/- 20.83
---------------------------------
| eval/              |          |
|    mean_ep_length  | 174      |
|    mean_reward     | -98      |
| time/              |          |
|    total_timesteps | 120000   |
| train/             |          |
|    actor_loss      | 6.48     |
|    critic_loss     | 0.249    |
|    learning_rate   | 0.001    |
|    n_updates       | 109999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 777      |
|    ep_rew_mean     | -101     |
| time/              |          |
|    episodes        | 220      |
|    fps             | 70       |
|    time_elapsed    | 1739     |
|    total_timesteps | 121882   |
| train/             |          |
|    actor_loss      | 4.14     |
|    critic_loss     | 0.821    |
|    learning_rate   | 0.001    |
|    n_updates       | 111881   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 784      |
|    ep_rew_mean     | -101     |
| time/              |          |
|    episodes        | 224      |
|    fps             | 69       |
|    time_elapsed    | 1757     |
|    total_timesteps | 122912   |
| train/             |          |
|    actor_loss      | 6.65     |
|    critic_loss     | 0.827    |
|    learning_rate   | 0.001    |
|    n_updates       | 112911   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 795      |
|    ep_rew_mean     | -100     |
| time/              |          |
|    episodes        | 228      |
|    fps             | 69       |
|    time_elapsed    | 1782     |
|    total_timesteps | 124342   |
| train/             |          |
|    actor_loss      | 4.33     |
|    critic_loss     | 0.347    |
|    learning_rate   | 0.001    |
|    n_updates       | 114341   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 820      |
|    ep_rew_mean     | -99.9    |
| time/              |          |
|    episodes        | 232      |
|    fps             | 69       |
|    time_elapsed    | 1831     |
|    total_timesteps | 127154   |
| train/             |          |
|    actor_loss      | 6.98     |
|    critic_loss     | 0.565    |
|    learning_rate   | 0.001    |
|    n_updates       | 117153   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 839      |
|    ep_rew_mean     | -98.3    |
| time/              |          |
|    episodes        | 236      |
|    fps             | 69       |
|    time_elapsed    | 1869     |
|    total_timesteps | 129371   |
| train/             |          |
|    actor_loss      | 4.25     |
|    critic_loss     | 0.254    |
|    learning_rate   | 0.001    |
|    n_updates       | 119370   |
---------------------------------
Eval num_timesteps=130000, episode_reward=-78.32 +/- 17.35
Episode length: 890.00 +/- 584.26
---------------------------------
| eval/              |          |
|    mean_ep_length  | 890      |
|    mean_reward     | -78.3    |
| time/              |          |
|    total_timesteps | 130000   |
| train/             |          |
|    actor_loss      | 6.72     |
|    critic_loss     | 0.145    |
|    learning_rate   | 0.001    |
|    n_updates       | 119999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 865      |
|    ep_rew_mean     | -97.4    |
| time/              |          |
|    episodes        | 240      |
|    fps             | 68       |
|    time_elapsed    | 1935     |
|    total_timesteps | 132963   |
| train/             |          |
|    actor_loss      | 8.74     |
|    critic_loss     | 1.15     |
|    learning_rate   | 0.001    |
|    n_updates       | 122962   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 903      |
|    ep_rew_mean     | -95.4    |
| time/              |          |
|    episodes        | 244      |
|    fps             | 68       |
|    time_elapsed    | 2010     |
|    total_timesteps | 137188   |
| train/             |          |
|    actor_loss      | 4.82     |
|    critic_loss     | 1.02     |
|    learning_rate   | 0.001    |
|    n_updates       | 127187   |
---------------------------------
Eval num_timesteps=140000, episode_reward=-68.65 +/- 46.05
Episode length: 1176.60 +/- 395.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.18e+03 |
|    mean_reward     | -68.7    |
| time/              |          |
|    total_timesteps | 140000   |
| train/             |          |
|    actor_loss      | 8.08     |
|    critic_loss     | 0.268    |
|    learning_rate   | 0.001    |
|    n_updates       | 129999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 931      |
|    ep_rew_mean     | -94.2    |
| time/              |          |
|    episodes        | 248      |
|    fps             | 67       |
|    time_elapsed    | 2071     |
|    total_timesteps | 140375   |
| train/             |          |
|    actor_loss      | 4.19     |
|    critic_loss     | 0.365    |
|    learning_rate   | 0.001    |
|    n_updates       | 130374   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 918      |
|    ep_rew_mean     | -91.5    |
| time/              |          |
|    episodes        | 252      |
|    fps             | 67       |
|    time_elapsed    | 2122     |
|    total_timesteps | 143271   |
| train/             |          |
|    actor_loss      | 6.06     |
|    critic_loss     | 0.523    |
|    learning_rate   | 0.001    |
|    n_updates       | 133270   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 936      |
|    ep_rew_mean     | -87.9    |
| time/              |          |
|    episodes        | 256      |
|    fps             | 67       |
|    time_elapsed    | 2233     |
|    total_timesteps | 149671   |
| train/             |          |
|    actor_loss      | 4.92     |
|    critic_loss     | 0.307    |
|    learning_rate   | 0.001    |
|    n_updates       | 139670   |
---------------------------------
Eval num_timesteps=150000, episode_reward=-36.56 +/- 1.73
Episode length: 1600.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.6e+03  |
|    mean_reward     | -36.6    |
| time/              |          |
|    total_timesteps | 150000   |
| train/             |          |
|    actor_loss      | 4.77     |
|    critic_loss     | 0.421    |
|    learning_rate   | 0.001    |
|    n_updates       | 139999   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 990      |
|    ep_rew_mean     | -82.6    |
| time/              |          |
|    episodes        | 260      |
|    fps             | 66       |
|    time_elapsed    | 2360     |
|    total_timesteps | 156400   |
| train/             |          |
|    actor_loss      | 8.15     |
|    critic_loss     | 0.374    |
|    learning_rate   | 0.001    |
|    n_updates       | 146399   |
---------------------------------
Eval num_timesteps=160000, episode_reward=-22.04 +/- 36.05
Episode length: 1579.00 +/- 42.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.58e+03 |
|    mean_reward     | -22      |
| time/              |          |
|    total_timesteps | 160000   |
| train/             |          |
|    actor_loss      | 4.48     |
|    critic_loss     | 0.32     |
|    learning_rate   | 0.001    |
|    n_updates       | 149999   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.02e+03 |
|    ep_rew_mean     | -76.7    |
| time/              |          |
|    episodes        | 264      |
|    fps             | 65       |
|    time_elapsed    | 2460     |
|    total_timesteps | 161600   |
| train/             |          |
|    actor_loss      | 2.49     |
|    critic_loss     | 0.468    |
|    learning_rate   | 0.001    |
|    n_updates       | 151599   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.02e+03 |
|    ep_rew_mean     | -70.6    |
| time/              |          |
|    episodes        | 268      |
|    fps             | 65       |
|    time_elapsed    | 2560     |
|    total_timesteps | 167204   |
| train/             |          |
|    actor_loss      | 5.13     |
|    critic_loss     | 0.47     |
|    learning_rate   | 0.001    |
|    n_updates       | 157203   |
---------------------------------
Eval num_timesteps=170000, episode_reward=74.24 +/- 76.03
Episode length: 1385.20 +/- 302.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.39e+03 |
|    mean_reward     | 74.2     |
| time/              |          |
|    total_timesteps | 170000   |
| train/             |          |
|    actor_loss      | 3.49     |
|    critic_loss     | 0.196    |
|    learning_rate   | 0.001    |
|    n_updates       | 159999   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 993      |
|    ep_rew_mean     | -67.6    |
| time/              |          |
|    episodes        | 272      |
|    fps             | 64       |
|    time_elapsed    | 2649     |
|    total_timesteps | 171891   |
| train/             |          |
|    actor_loss      | 3.39     |
|    critic_loss     | 0.821    |
|    learning_rate   | 0.001    |
|    n_updates       | 161890   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 993      |
|    ep_rew_mean     | -59      |
| time/              |          |
|    episodes        | 276      |
|    fps             | 64       |
|    time_elapsed    | 2762     |
|    total_timesteps | 178291   |
| train/             |          |
|    actor_loss      | 5.1      |
|    critic_loss     | 0.236    |
|    learning_rate   | 0.001    |
|    n_updates       | 168290   |
---------------------------------
Eval num_timesteps=180000, episode_reward=58.37 +/- 138.79
Episode length: 984.60 +/- 616.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 985      |
|    mean_reward     | 58.4     |
| time/              |          |
|    total_timesteps | 180000   |
| train/             |          |
|    actor_loss      | 5.21     |
|    critic_loss     | 0.718    |
|    learning_rate   | 0.001    |
|    n_updates       | 169999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 960      |
|    ep_rew_mean     | -56.3    |
| time/              |          |
|    episodes        | 280      |
|    fps             | 64       |
|    time_elapsed    | 2832     |
|    total_timesteps | 182025   |
| train/             |          |
|    actor_loss      | 6.19     |
|    critic_loss     | 1.09     |
|    learning_rate   | 0.001    |
|    n_updates       | 172024   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 943      |
|    ep_rew_mean     | -50.5    |
| time/              |          |
|    episodes        | 284      |
|    fps             | 64       |
|    time_elapsed    | 2905     |
|    total_timesteps | 186137   |
| train/             |          |
|    actor_loss      | 3.84     |
|    critic_loss     | 2.11     |
|    learning_rate   | 0.001    |
|    n_updates       | 176136   |
---------------------------------
Eval num_timesteps=190000, episode_reward=184.40 +/- 15.63
Episode length: 1600.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.6e+03  |
|    mean_reward     | 184      |
| time/              |          |
|    total_timesteps | 190000   |
| train/             |          |
|    actor_loss      | 3.29     |
|    critic_loss     | 0.509    |
|    learning_rate   | 0.001    |
|    n_updates       | 179999   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 992      |
|    ep_rew_mean     | -38      |
| time/              |          |
|    episodes        | 288      |
|    fps             | 63       |
|    time_elapsed    | 3038     |
|    total_timesteps | 193200   |
| train/             |          |
|    actor_loss      | 4.46     |
|    critic_loss     | 0.184    |
|    learning_rate   | 0.001    |
|    n_updates       | 183199   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.02e+03 |
|    ep_rew_mean     | -29.4    |
| time/              |          |
|    episodes        | 292      |
|    fps             | 63       |
|    time_elapsed    | 3126     |
|    total_timesteps | 198119   |
| train/             |          |
|    actor_loss      | 5.15     |
|    critic_loss     | 0.541    |
|    learning_rate   | 0.001    |
|    n_updates       | 188118   |
---------------------------------
Eval num_timesteps=200000, episode_reward=207.80 +/- 2.82
Episode length: 1600.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.6e+03  |
|    mean_reward     | 208      |
| time/              |          |
|    total_timesteps | 200000   |
| train/             |          |
|    actor_loss      | 2.5      |
|    critic_loss     | 0.598    |
|    learning_rate   | 0.001    |
|    n_updates       | 189999   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.04e+03 |
|    ep_rew_mean     | -18.4    |
| time/              |          |
|    episodes        | 296      |
|    fps             | 62       |
|    time_elapsed    | 3251     |
|    total_timesteps | 204800   |
| train/             |          |
|    actor_loss      | 0.889    |
|    critic_loss     | 0.391    |
|    learning_rate   | 0.001    |
|    n_updates       | 194799   |
---------------------------------
Eval num_timesteps=210000, episode_reward=261.69 +/- 7.29
Episode length: 1600.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.6e+03  |
|    mean_reward     | 262      |
| time/              |          |
|    total_timesteps | 210000   |
| train/             |          |
|    actor_loss      | 3.86     |
|    critic_loss     | 0.448    |
|    learning_rate   | 0.001    |
|    n_updates       | 199999   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.03e+03 |
|    ep_rew_mean     | -6.44    |
| time/              |          |
|    episodes        | 300      |
|    fps             | 62       |
|    time_elapsed    | 3383     |
|    total_timesteps | 211600   |
| train/             |          |
|    actor_loss      | 2.4      |
|    critic_loss     | 0.351    |
|    learning_rate   | 0.001    |
|    n_updates       | 201599   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.01e+03 |
|    ep_rew_mean     | 1.23     |
| time/              |          |
|    episodes        | 304      |
|    fps             | 62       |
|    time_elapsed    | 3453     |
|    total_timesteps | 215559   |
| train/             |          |
|    actor_loss      | -0.341   |
|    critic_loss     | 0.206    |
|    learning_rate   | 0.001    |
|    n_updates       | 205558   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 998      |
|    ep_rew_mean     | 8.28     |
| time/              |          |
|    episodes        | 308      |
|    fps             | 62       |
|    time_elapsed    | 3516     |
|    total_timesteps | 219068   |
| train/             |          |
|    actor_loss      | -0.255   |
|    critic_loss     | 0.271    |
|    learning_rate   | 0.001    |
|    n_updates       | 209067   |
---------------------------------
Eval num_timesteps=220000, episode_reward=287.75 +/- 0.58
Episode length: 1322.80 +/- 40.44
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.32e+03 |
|    mean_reward     | 288      |
| time/              |          |
|    total_timesteps | 220000   |
| train/             |          |
|    actor_loss      | 1.51     |
|    critic_loss     | 0.975    |
|    learning_rate   | 0.001    |
|    n_updates       | 209999   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 993      |
|    ep_rew_mean     | 19.3     |
| time/              |          |
|    episodes        | 312      |
|    fps             | 62       |
|    time_elapsed    | 3610     |
|    total_timesteps | 223994   |
| train/             |          |
|    actor_loss      | -1.22    |
|    critic_loss     | 1.4      |
|    learning_rate   | 0.001    |
|    n_updates       | 213993   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.03e+03 |
|    ep_rew_mean     | 30.6     |
| time/              |          |
|    episodes        | 316      |
|    fps             | 61       |
|    time_elapsed    | 3682     |
|    total_timesteps | 228090   |
| train/             |          |
|    actor_loss      | -0.092   |
|    critic_loss     | 0.65     |
|    learning_rate   | 0.001    |
|    n_updates       | 218089   |
---------------------------------
Eval num_timesteps=230000, episode_reward=166.54 +/- 155.16
Episode length: 932.60 +/- 431.23
---------------------------------
| eval/              |          |
|    mean_ep_length  | 933      |
|    mean_reward     | 167      |
| time/              |          |
|    total_timesteps | 230000   |
| train/             |          |
|    actor_loss      | -0.444   |
|    critic_loss     | 0.433    |
|    learning_rate   | 0.001    |
|    n_updates       | 219999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.06e+03 |
|    ep_rew_mean     | 46.2     |
| time/              |          |
|    episodes        | 320      |
|    fps             | 61       |
|    time_elapsed    | 3788     |
|    total_timesteps | 233819   |
| train/             |          |
|    actor_loss      | 0.989    |
|    critic_loss     | 1.95     |
|    learning_rate   | 0.001    |
|    n_updates       | 223818   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.09e+03 |
|    ep_rew_mean     | 59.3     |
| time/              |          |
|    episodes        | 324      |
|    fps             | 61       |
|    time_elapsed    | 3865     |
|    total_timesteps | 238013   |
| train/             |          |
|    actor_loss      | -0.8     |
|    critic_loss     | 2.56     |
|    learning_rate   | 0.001    |
|    n_updates       | 228012   |
---------------------------------
Eval num_timesteps=240000, episode_reward=163.53 +/- 99.21
Episode length: 1287.20 +/- 281.18
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.29e+03 |
|    mean_reward     | 164      |
| time/              |          |
|    total_timesteps | 240000   |
| train/             |          |
|    actor_loss      | -2.43    |
|    critic_loss     | 0.859    |
|    learning_rate   | 0.001    |
|    n_updates       | 229999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.13e+03 |
|    ep_rew_mean     | 73.3     |
| time/              |          |
|    episodes        | 328      |
|    fps             | 61       |
|    time_elapsed    | 3971     |
|    total_timesteps | 243595   |
| train/             |          |
|    actor_loss      | -2.66    |
|    critic_loss     | 0.182    |
|    learning_rate   | 0.001    |
|    n_updates       | 233594   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.14e+03 |
|    ep_rew_mean     | 88.7     |
| time/              |          |
|    episodes        | 332      |
|    fps             | 61       |
|    time_elapsed    | 4057     |
|    total_timesteps | 248253   |
| train/             |          |
|    actor_loss      | -2.95    |
|    critic_loss     | 0.533    |
|    learning_rate   | 0.001    |
|    n_updates       | 238252   |
---------------------------------
Eval num_timesteps=250000, episode_reward=297.12 +/- 0.68
Episode length: 1060.60 +/- 7.23
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.06e+03 |
|    mean_reward     | 297      |
| time/              |          |
|    total_timesteps | 250000   |
| train/             |          |
|    actor_loss      | -4.46    |
|    critic_loss     | 0.149    |
|    learning_rate   | 0.001    |
|    n_updates       | 239999   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.17e+03 |
|    ep_rew_mean     | 103      |
| time/              |          |
|    episodes        | 336      |
|    fps             | 61       |
|    time_elapsed    | 4152     |
|    total_timesteps | 253350   |
| train/             |          |
|    actor_loss      | -4.34    |
|    critic_loss     | 0.309    |
|    learning_rate   | 0.001    |
|    n_updates       | 243349   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.18e+03 |
|    ep_rew_mean     | 118      |
| time/              |          |
|    episodes        | 340      |
|    fps             | 60       |
|    time_elapsed    | 4229     |
|    total_timesteps | 257600   |
| train/             |          |
|    actor_loss      | -4.22    |
|    critic_loss     | 0.135    |
|    learning_rate   | 0.001    |
|    n_updates       | 247599   |
---------------------------------
Eval num_timesteps=260000, episode_reward=305.31 +/- 0.44
Episode length: 981.20 +/- 4.96
---------------------------------
| eval/              |          |
|    mean_ep_length  | 981      |
|    mean_reward     | 305      |
| time/              |          |
|    total_timesteps | 260000   |
| train/             |          |
|    actor_loss      | -5.23    |
|    critic_loss     | 0.109    |
|    learning_rate   | 0.001    |
|    n_updates       | 249999   |
---------------------------------
New best mean reward!
Stopping training because the mean reward 305.31  is above the threshold 300
Training complete. Model saved.
Plotting sample efficiency...
Evaluating model...
Seed 2024: mean_reward:270.48 +/- 94.06
